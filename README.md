# Autonomous Driving: Perception and Object Detection

This repository demonstrates an end-to-end pipeline for perception and object detection in autonomous driving systems. It combines lane topology prediction, 3D object localization, and environmental perception to optimize navigation and safety in autonomous vehicles.

---

## **Project Highlights**

- **Dataset:** Leveraged the **OpenLane-V2** dataset for accurate lane topology prediction and 3D localization.
- **Object Detection:** Fine-tuned the **YOLO** model for high-accuracy detection of traffic signs, vehicles, and other road objects.
- **Depth Estimation:** Integrated **DepthAnythingV2** to enhance 3D spatial awareness and depth perception.
- **360Â° Environmental Perception:** Developed panoramic image blending techniques using multi-camera inputs for complete situational awareness.
- **Visualization:** Utilized **Matplotlib** and **NumPy** for data analysis and visualization of results.

---

## **Tech Stack**

- **Programming Language:** Python
- **Deep Learning Frameworks:** PyTorch
- **Key Libraries:** NumPy, Matplotlib
- **Models:** YOLO, DepthAnythingV2
- **Dataset:** OpenLane-V2

---

## **Project Structure**


---

---

## **Installation**

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/AutonomousDriving-PerceptionDetection.git
   cd AutonomousDriving-PerceptionDetection```

2.	Install dependencies:
   ```pip install -r requirements.txt```
